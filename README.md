# Building GPT from scratch
In this repo I build a tiny GPT (transformer) model from scratch to run it on cpu, following Andrej Karpathy's lecture: https://www.youtube.com/watch?v=kCc8FmEb1nY&t=658s

"Attention is all you need" paper: https://arxiv.org/abs/1706.03762

nanoGPT: https://github.com/karpathy/nanoGPT

